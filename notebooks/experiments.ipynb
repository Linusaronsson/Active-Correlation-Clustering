{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we present how to generate all results and then plot the figures. Finishing all experiments may be quite slow unless you have access to multiples CPUs. Consequently, we have included all finished results in the folder \"experiment_results_local\" such that you do not need to run all of them locally. If you just want to generate results, skip to \"Generating results\" below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we define a config for the experiments to be executed. You may exclude \"COBRAS\" and \"nCOBRAS\" as they can be quite slow (nCOBRAS in particular). QECC is also the more interesting baseline since it is based on correlation clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"_experiment_name\": \"acc_experiment\",\n",
    "    \"_num_repeats\": 8,\n",
    "    \"_n_workers\": 8,\n",
    "    \"_verbose\": True,\n",
    "    \"_overwrite\": False,\n",
    "\n",
    "    \"seed\": [14],\n",
    "    \"batch_size\": [0.001],\n",
    "    \"noise_level\": [0.2, 0.4],\n",
    "    \"warm_start\": [0],\n",
    "    \"K_init\": 10,\n",
    "    \"sim_init\": [0.1],\n",
    "    \"sim_init_type\": [\"random_clustering\", \"kmeans\"],\n",
    "    \"acq_fn\": [\"unif\", \"uncert\", \"freq\", \"maxmin\", \"maxexp\", \"QECC\", \"COBRAS\", \"nCOBRAS\"],\n",
    "    \"eps\": [0.3],\n",
    "    \"beta\": [1],\n",
    "    \"tau\": [3],\n",
    "    \"num_maxmin_edges\": -1,\n",
    "\n",
    "    \"dataset_name\": [\"synthetic\", \"20newsgroups\", \"cifar10\", \"mnist\", \"mushrooms\", \"cardiotocography\", \"ecoli\", \"forest_type_mapping\", \"user_knowledge\", \"yeast\"],\n",
    "\n",
    "    \"dataset_n_samples\": 500,\n",
    "    \"dataset_n_clusters\": [10],\n",
    "    \"dataset_class_balance\": [None],\n",
    "    \"dataset_class_sep\": [1.5],\n",
    "    \"dataset_n_features\": [10],\n",
    "    \"dataset_y_flip\": [0],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell below generates a .json config file based on the config above. The options in \"options_to_keep\" correspond to options with more than one value: noise level (2 options), sim_init_type (2 options), acq_fn (8 options) and dataset_name (10 options). Each experiment is repeated 8 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acc.experiment_data import ExperimentReader\n",
    "er = ExperimentReader()\n",
    "start_index = 1\n",
    "start_index = er.generate_experiments(\n",
    "    folder=\"../configs/acc_experiment\",\n",
    "    options_to_keep=[\"noise_level\", \"sim_init_type\", \"acq_fn\", \"dataset_name\"],\n",
    "    start_index=start_index, \n",
    "    **config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following terminal command **when located in the root folder of the repository**. This runs all combinations of experiments in the above config file. In other words, 8 * 2 * 2 * 8 * 10 = 2560 jobs. The \"_n_workers\" specifies how many jobs to run in parallel (i.e., how many cores of your CPU to use). See bottom of notebook for how to parellelize this across multiple CPUs, as this will be very slow on one CPU. Alternatively, you can modify the config to only run the jobs you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python acc/run_experiments.py --config=configs/acc_experiment/experiment1.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating results\n",
    "\n",
    "After the command above finishes all experiment results is saved to the folder \"experiment_results_local\". Because this can be slow, we have already finished the experiments and placed the results in the folder \"experiment_results\". We now illustrate how plots can be generated based on the results. After running the two cells below, plots for all datasets (and other parameters) can be found in \"../plots/acc_experiment/\". You can modify the config if you only want to generate results for a subset of the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acc.experiment_data import ExperimentReader\n",
    "er = ExperimentReader(metrics=[\"rand\", \"ami\", \"num_repeat_queries\", \"num_violations\", \"time_select_batch\"])\n",
    "data = er.read_all_data(folder=\"../experiment_results/acc_experiment\")\n",
    "\n",
    "#data = er.read_all_data(folder=\"../experiment_results_local/acc_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33384\\1662718011.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m }\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m er.generate_AL_curves(\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0msave_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"../plots/acc_experiment/\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\github_projects\\active-correlation-clustering\\acc\\experiment_data.py\u001b[0m in \u001b[0;36mgenerate_AL_curves\u001b[1;34m(self, data, save_location, categorize, compare, options_in_file_name, err_style, marker, markersize, capsize, linestyle, prop, **config)\u001b[0m\n\u001b[0;32m    217\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No data for these options @@@@@@@\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m                 \u001b[0mdf_filtered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_filtered\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_data_column_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_column_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_location\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\github_projects\\active-correlation-clustering\\acc\\experiment_data.py\u001b[0m in \u001b[0;36mflatten_dataframe\u001b[1;34m(self, df, non_data_column_names, data_column_names)\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                 \u001b[0mdf_expanded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[0mdf_expanded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'x2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnon_data_column_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Linus\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Linus\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mreset_index\u001b[1;34m(self, level, drop, name, inplace)\u001b[0m\n\u001b[0;32m   1492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1493\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1494\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1496\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Linus\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Linus\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[1;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[0;32m   5842\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlab\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5843\u001b[0m                     \u001b[1;31m# if we have the codes, extract the values with a mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5844\u001b[1;33m                     level_values = algorithms.take(\n\u001b[0m\u001b[0;32m   5845\u001b[0m                         \u001b[0mlevel_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_na_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5846\u001b[0m                     )\n",
      "\u001b[1;32mc:\\Users\\Linus\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(arr, indices, axis, allow_fill, fill_value)\u001b[0m\n\u001b[0;32m   1437\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m     \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "    \"_experiment_name\": \"acc_experiment\",\n",
    "    \"_num_repeats\": 8,\n",
    "    \"_n_workers\": 8,\n",
    "    \"_verbose\": True,\n",
    "    \"_overwrite\": False,\n",
    "\n",
    "    \"seed\": [14],\n",
    "    \"batch_size\": [0.001],\n",
    "    \"noise_level\": [0.2, 0.4],\n",
    "    \"warm_start\": [0],\n",
    "    \"K_init\": 10,\n",
    "    \"sim_init\": [0.1],\n",
    "    \"sim_init_type\": [\"random_clustering\", \"kmeans\"],\n",
    "    \"acq_fn\": [\"unif\", \"uncert\", \"freq\", \"maxmin\", \"maxexp\", \"QECC\", \"COBRAS\", \"nCOBRAS\"],\n",
    "    \"eps\": [0.3],\n",
    "    \"beta\": [1],\n",
    "    \"tau\": [3],\n",
    "    \"num_maxmin_edges\": -1,\n",
    "\n",
    "    \"dataset_name\": [\"synthetic\", \"20newsgroups\", \"cifar10\", \"mnist\", \"mushrooms\", \"cardiotocography\", \"ecoli\", \"forest_type_mapping\", \"user_knowledge\", \"yeast\"],\n",
    "\n",
    "    \"dataset_n_samples\": 500,\n",
    "    \"dataset_n_clusters\": [10],\n",
    "    \"dataset_class_balance\": [None],\n",
    "    \"dataset_class_sep\": [1.5],\n",
    "    \"dataset_n_features\": [10],\n",
    "    \"dataset_y_flip\": [0],\n",
    "}\n",
    "\n",
    "er.generate_AL_curves(\n",
    "    data,\n",
    "    save_location=\"../plots/acc_experiment/\",\n",
    "    categorize=[\"dataset_name\"],\n",
    "    compare=[\"acq_fn\"],\n",
    "    options_in_file_name=[\"noise_level\", \"sim_init_type\"],\n",
    "    err_style=\"band\",\n",
    "    marker=\"o\",\n",
    "    markersize=6,\n",
    "    capsize=6,\n",
    "    linestyle=\"solid\",\n",
    "    prop=True,\n",
    "    **config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running experiment on multiple CPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works the same as above, except we now leave the \"options_to_keep\" parameter empty. This means it will generate one .json file for each experiment (where each experiment will be repeated 8 times). In total we get 240 .json files, each of which can be run on its own CPU. Each CPU can then run all 8 repeats in parallel on 1 core each.\n",
    "\n",
    "This assumes access to a compute cluster with multiple CPUs. If you have access to this, it should be straightforward how to distribute them to each CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acc.experiment_data import ExperimentReader\n",
    "er = ExperimentReader()\n",
    "start_index = 1\n",
    "config = {\n",
    "    \"_experiment_name\": \"acc_experiment\",\n",
    "    \"_num_repeats\": 8,\n",
    "    \"_n_workers\": 8,\n",
    "    \"_verbose\": True,\n",
    "    \"_overwrite\": False,\n",
    "\n",
    "    \"seed\": [14],\n",
    "    \"batch_size\": [0.001],\n",
    "    \"noise_level\": [0.2, 0.4],\n",
    "    \"warm_start\": [0],\n",
    "    \"K_init\": 10,\n",
    "    \"sim_init\": [0.1],\n",
    "    \"sim_init_type\": [\"random_clustering\", \"kmeans\"],\n",
    "    \"acq_fn\": [\"unif\", \"uncert\", \"freq\", \"maxmin\", \"maxexp\", \"QECC\", \"COBRAS\", \"nCOBRAS\"],\n",
    "    \"eps\": [0.3],\n",
    "    \"beta\": [1],\n",
    "    \"tau\": [3],\n",
    "    \"num_maxmin_edges\": -1,\n",
    "\n",
    "    \"dataset_name\": [\"mnist\", \"mushrooms\"],\n",
    "\n",
    "    \"dataset_n_samples\": 500,\n",
    "    \"dataset_n_clusters\": [10],\n",
    "    \"dataset_class_balance\": [None],\n",
    "    \"dataset_class_sep\": [1.5],\n",
    "    \"dataset_n_features\": [10],\n",
    "    \"dataset_y_flip\": [0],\n",
    "}\n",
    "start_index = er.generate_experiments(\n",
    "    folder=\"../configs/acc_experiment\",\n",
    "    options_to_keep=[],\n",
    "    start_index=start_index, \n",
    "    **config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
