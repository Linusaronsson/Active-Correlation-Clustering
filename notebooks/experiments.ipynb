{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we present how to generate all results and then plot the figures. Finishing all experiments may be quite slow unless you have access to multiples CPUs. Consequently, we have included all finished results in the folder \"experiment_results_local\" such that you do not need to run all of them locally. If you just want to generate results, skip to \"Generating results\" below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we define a config for the experiments to be executed. You may exclude \"COBRAS\" and \"nCOBRAS\" as they can be quite slow (nCOBRAS in particular). QECC is also the more interesting baseline since it is based on correlation clustering. (Note: the last 6 dataset related options are only relevant if dataset_name = \"synthetic\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"_experiment_name\": \"acc_experiment\",\n",
    "    \"_num_repeats\": 8,\n",
    "    \"_n_workers\": 8,\n",
    "    \"_verbose\": True,\n",
    "    \"_overwrite\": False,\n",
    "\n",
    "    \"seed\": [14],\n",
    "    \"batch_size\": [0.001],\n",
    "    \"noise_level\": [0.2, 0.4],\n",
    "    \"warm_start\": [0],\n",
    "    \"K_init\": 10,\n",
    "    \"sim_init\": [0.1],\n",
    "    \"sim_init_type\": [\"random_clustering\", \"kmeans\"],\n",
    "    \"acq_fn\": [\"unif\", \"uncert\", \"freq\", \"maxmin\", \"maxexp\", \"QECC\", \"COBRAS\", \"nCOBRAS\"],\n",
    "    \"eps\": [0.3],\n",
    "    \"beta\": [1],\n",
    "    \"tau\": [3],\n",
    "    \"num_maxmin_edges\": -1,\n",
    "\n",
    "    \"dataset_name\": [\"synthetic\", \"20newsgroups\", \"cifar10\", \"mnist\", \"mushrooms\", \"cardiotocography\", \"ecoli\", \"forest_type_mapping\", \"user_knowledge\", \"yeast\"],\n",
    "\n",
    "    \"dataset_n_samples\": 500,\n",
    "    \"dataset_n_clusters\": [10],\n",
    "    \"dataset_class_balance\": [None],\n",
    "    \"dataset_class_sep\": [1.5],\n",
    "    \"dataset_n_features\": [10],\n",
    "    \"dataset_y_flip\": [0],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell below generates a .json config file based on the config above. The options in \"options_to_keep\" correspond to options with more than one value: noise level (2 options), sim_init_type (2 options), acq_fn (8 options) and dataset_name (10 options). Each experiment is repeated 8 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acc.experiment_data import ExperimentReader\n",
    "er = ExperimentReader()\n",
    "start_index = 1\n",
    "start_index = er.generate_experiments(\n",
    "    folder=\"../configs/acc_experiment\",\n",
    "    options_to_keep=[\"noise_level\", \"sim_init_type\", \"acq_fn\", \"dataset_name\"],\n",
    "    start_index=start_index, \n",
    "    **config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following terminal command **when located in the root folder of the repository**. This runs all combinations of experiments in the above config file. In other words, 8 * 2 * 2 * 8 * 10 = 2560 jobs. The \"_n_workers\" specifies how many jobs to run in parallel (i.e., how many cores of your CPU to use). See bottom of notebook for how to parellelize this across multiple CPUs, as this will be very slow on one CPU. Alternatively, you can modify the config to only run the jobs you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python acc/run_experiments.py --config=configs/acc_experiment/experiment1.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating results\n",
    "\n",
    "After the command above finishes all experiment results is saved to the folder \"experiment_results_local\". Because this can be slow, we have already finished the experiments and placed the results in the folder \"experiment_results\". We now illustrate how plots can be generated based on the results. After running the two cells below, plots for all datasets (and other parameters) can be found in \"../plots/acc_experiment/\". You can modify the config if you only want to generate results for a subset of the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acc.experiment_data import ExperimentReader\n",
    "er = ExperimentReader(metrics=[\"rand\", \"ami\", \"num_repeat_queries\", \"num_violations\", \"time_select_batch\"])\n",
    "data = er.read_all_data(folder=\"../experiment_results/acc_experiment\")\n",
    "\n",
    "# uncomment to load data from your locally executed experiments\n",
    "#data = er.read_all_data(folder=\"../experiment_results_local/acc_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"_experiment_name\": \"acc_experiment\",\n",
    "    \"_num_repeats\": 8,\n",
    "    \"_n_workers\": 8,\n",
    "    \"_verbose\": True,\n",
    "    \"_overwrite\": False,\n",
    "\n",
    "    \"seed\": [14],\n",
    "    \"batch_size\": [0.001],\n",
    "    \"noise_level\": [0.2, 0.4],\n",
    "    \"warm_start\": [0],\n",
    "    \"K_init\": 10,\n",
    "    \"sim_init\": [0.1],\n",
    "    \"sim_init_type\": [\"random_clustering\", \"kmeans\"],\n",
    "    \"acq_fn\": [\"unif\", \"uncert\", \"freq\", \"maxmin\", \"maxexp\", \"QECC\", \"COBRAS\", \"nCOBRAS\"],\n",
    "    \"eps\": [0.3],\n",
    "    \"beta\": [1],\n",
    "    \"tau\": [3],\n",
    "    \"num_maxmin_edges\": -1,\n",
    "\n",
    "    \"dataset_name\": [\"synthetic\", \"20newsgroups\", \"cifar10\", \"mnist\", \"mushrooms\", \"cardiotocography\", \"ecoli\", \"forest_type_mapping\", \"user_knowledge\", \"yeast\"],\n",
    "\n",
    "    \"dataset_n_samples\": 500,\n",
    "    \"dataset_n_clusters\": [10],\n",
    "    \"dataset_class_balance\": [None],\n",
    "    \"dataset_class_sep\": [1.5],\n",
    "    \"dataset_n_features\": [10],\n",
    "    \"dataset_y_flip\": [0],\n",
    "}\n",
    "\n",
    "er.generate_AL_curves(\n",
    "    data,\n",
    "    save_location=\"../plots/acc_experiment/\",\n",
    "    categorize=[],\n",
    "    compare=[\"acq_fn\"],\n",
    "    options_in_file_name=[\"dataset_name\", \"noise_level\", \"sim_init_type\"],\n",
    "    prop=True,\n",
    "    **config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running experiment on multiple CPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works the same as above, except we now leave the \"options_to_keep\" parameter empty. This means it will generate one .json file for each experiment (where each experiment will be repeated 8 times). In total we get 320 .json files, each of which can be run on its own CPU. Each CPU will then (if possible) run all 8 repeats in parallel on 1 core each.\n",
    "\n",
    "This assumes access to a compute cluster with multiple CPUs. If you have access to this, it should be straightforward how to distribute them to each CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acc.experiment_data import ExperimentReader\n",
    "er = ExperimentReader()\n",
    "start_index = 1\n",
    "\n",
    "config = {\n",
    "    \"_experiment_name\": \"acc_experiment\",\n",
    "    \"_num_repeats\": 8,\n",
    "    \"_n_workers\": 8,\n",
    "    \"_verbose\": True,\n",
    "    \"_overwrite\": False,\n",
    "\n",
    "    \"seed\": [14],\n",
    "    \"batch_size\": [0.001],\n",
    "    \"noise_level\": [0.2, 0.4],\n",
    "    \"warm_start\": [0],\n",
    "    \"K_init\": 10,\n",
    "    \"sim_init\": [0.1],\n",
    "    \"sim_init_type\": [\"random_clustering\", \"kmeans\"],\n",
    "    \"acq_fn\": [\"unif\", \"uncert\", \"freq\", \"maxmin\", \"maxexp\", \"QECC\", \"COBRAS\", \"nCOBRAS\"],\n",
    "    \"eps\": [0.3],\n",
    "    \"beta\": [1],\n",
    "    \"tau\": [3],\n",
    "    \"num_maxmin_edges\": -1,\n",
    "\n",
    "    \"dataset_name\": [\"synthetic\", \"20newsgroups\", \"cifar10\", \"mnist\", \"mushrooms\", \"cardiotocography\", \"ecoli\", \"forest_type_mapping\", \"user_knowledge\", \"yeast\"],\n",
    "\n",
    "    \"dataset_n_samples\": 500,\n",
    "    \"dataset_n_clusters\": [10],\n",
    "    \"dataset_class_balance\": [None],\n",
    "    \"dataset_class_sep\": [1.5],\n",
    "    \"dataset_n_features\": [10],\n",
    "    \"dataset_y_flip\": [0],\n",
    "}\n",
    "\n",
    "start_index = er.generate_experiments(\n",
    "    folder=\"../configs/acc_experiment\",\n",
    "    options_to_keep=[],\n",
    "    start_index=start_index, \n",
    "    **config\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
