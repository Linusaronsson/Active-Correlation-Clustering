{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "from rac.correlation_clustering import max_correlation_dynamic_K\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, v_measure_score\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "def test_dataset(X, Y, seed=1):\n",
    "    n_classes = len(np.unique(Y))\n",
    "    kmeans = KMeans(n_clusters=n_classes, random_state=seed).fit(X)\n",
    "    print(\"kmeans score: \", adjusted_rand_score(Y, kmeans.labels_))\n",
    "\n",
    "    X_sc = preprocessing.StandardScaler().fit_transform(X)\n",
    "    kmeans = KMeans(n_clusters=n_classes, random_state=seed).fit(X_sc)\n",
    "    print(\"kmeans score (SC): \", adjusted_rand_score(Y, kmeans.labels_))\n",
    "\n",
    "    X_mm = preprocessing.MinMaxScaler().fit_transform(X)\n",
    "    kmeans = KMeans(n_clusters=n_classes, random_state=seed).fit(X_mm)\n",
    "    print(\"kmeans score (MM): \", adjusted_rand_score(Y, kmeans.labels_))\n",
    "\n",
    "def random_data_sample(X, Y, size, rs):\n",
    "    if size <= 1:\n",
    "        num_samples = int(len(Y)*size)\n",
    "    else:\n",
    "        num_samples = np.minimum(size, len(Y))\n",
    "    inds = rs.choice(len(Y), num_samples)\n",
    "    return X[inds], Y[inds]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cats = [\"rec.sport.baseball\", \"soc.religion.christian\", \"rec.autos\", \"talk.politics.mideast\", \"misc.forsale\"]\n",
    "data = datasets.fetch_20newsgroups(data_home=\"../datasets/\", subset=\"all\", categories=cats)\n",
    "Y = data.target\n",
    "X = data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "normalize = True\n",
    "document_embeddings = TransformerDocumentEmbeddings('distilbert-base-uncased', fine_tune=True)\n",
    "data = None\n",
    "for sen in X:\n",
    "    sentence = Sentence(sen)\n",
    "    document_embeddings.embed(sentence)\n",
    "    dat = sentence.get_embedding()\n",
    "    if data is None:\n",
    "        data = dat.cpu().numpy().reshape(1, 768)\n",
    "    else:\n",
    "        data = np.vstack((data, dat.cpu().numpy().reshape(1, 768)))\n",
    "X = data\n",
    "#np.save(\"datasets/20newsgroups_small.npy\", X)\n",
    "#X = np.load(\"20newsgroups.npy\")\n",
    "#X = TfidfVectorizer().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18846, 768)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "data = datasets.fetch_20newsgroups(data_home=\"../datasets/20newsgroups_data/\", subset=\"all\")\n",
    "Y = data.target\n",
    "X = np.load(\"../datasets/20newsgroups_data/20newsgroups.npy\")\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "X = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(19)\n",
    "X_sample, Y_sample = random_data_sample(X, Y, 1000, rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans score:  0.2314524110145444\n",
      "kmeans score (SC):  0.24636367652759042\n",
      "kmeans score (MM):  0.25051530744696626\n"
     ]
    }
   ],
   "source": [
    "test_dataset(X_sample, Y_sample, seed=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = preprocessing.MinMaxScaler().fit_transform(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 50)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"../datasets/20newsgroups_data/X.npy\", X_sample)\n",
    "#np.save(\"../datasets/20newsgroups_data/Y.npy\", Y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = np.load(\"../datasets/20newsgroups_data/X.npy\")\n",
    "Y_sample = np.load(\"../datasets/20newsgroups_data/Y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19]),\n",
       " array([46, 57, 45, 48, 63, 47, 48, 65, 51, 53, 39, 57, 46, 56, 65, 47, 52,\n",
       "        48, 38, 29], dtype=int64))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_sample, return_counts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see cifar10_prep.ipynb for the code to prepare embeddings\n",
    "X = np.load(\"../datasets/cifar10_data/cifar10_embedding.npy\")\n",
    "Y = np.load(\"../datasets/cifar10_data/cifar10_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "X = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(19)\n",
    "X_sample, Y_sample = random_data_sample(X, Y, 1000, rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans score:  0.6773329544559815\n",
      "kmeans score (SC):  0.6594862669369495\n",
      "kmeans score (MM):  0.6861314428049142\n"
     ]
    }
   ],
   "source": [
    "test_dataset(X_sample, Y_sample, seed=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"../datasets/cifar10_data/X.npy\", X_sample)\n",
    "#np.save(\"../datasets/cifar10_data/Y.npy\", Y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = np.load(\"../datasets/cifar10_data/X.npy\")\n",
    "Y_sample = np.load(\"../datasets/cifar10_data/Y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([ 91,  96, 107,  89,  99, 113,  96,  93, 112, 104], dtype=int64))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_sample, return_counts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mushrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mushroom = fetch_ucirepo(id=73) \n",
    "X = mushroom.data.features \n",
    "Y = mushroom.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Linus\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "Y = label_encoder.fit_transform(Y)\n",
    "X = pd.get_dummies(X, columns=X.columns).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(19)\n",
    "X_sample, Y_sample = random_data_sample(X, Y, 1000, rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 116)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans score:  0.611150390579939\n",
      "kmeans score (SC):  0.5179268416222097\n",
      "kmeans score (MM):  0.611150390579939\n"
     ]
    }
   ],
   "source": [
    "test_dataset(X_sample, Y_sample, seed=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([503, 497], dtype=int64))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_sample, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"../datasets/mushrooms_data/X.npy\", X_sample)\n",
    "#np.save(\"../datasets/mushrooms_data/Y.npy\", Y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = np.load(\"../datasets/mushrooms_data/X.npy\")\n",
    "Y_sample = np.load(\"../datasets/mushrooms_data/Y.npy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "X = breast_cancer_wisconsin_diagnostic.data.features.values\n",
    "Y = breast_cancer_wisconsin_diagnostic.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y['Diagnosis'].map({'M': 1, 'B': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(19)\n",
    "X_sample, Y_sample = random_data_sample(X, Y, 1000, rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([356, 213], dtype=int64))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_sample, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans score:  0.486626341880326\n",
      "kmeans score (SC):  0.7186399055093501\n",
      "kmeans score (MM):  0.8050419613541757\n"
     ]
    }
   ],
   "source": [
    "test_dataset(X_sample, Y_sample, seed=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = preprocessing.MinMaxScaler().fit_transform(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"../datasets/breast_cancer_data/X.npy\", X_sample)\n",
    "#np.save(\"../datasets/breast_cancer_data/Y.npy\", Y_sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cardiotocography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "cardiotocography = fetch_ucirepo(id=193) \n",
    "X = cardiotocography.data.features.values\n",
    "Y = cardiotocography.data.targets \n",
    "Y = Y['CLASS'].to_numpy().astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>DP</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>...</th>\n",
       "      <th>Width</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>137</td>\n",
       "      <td>121</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>68</td>\n",
       "      <td>198</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>136</td>\n",
       "      <td>140</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>68</td>\n",
       "      <td>198</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>135</td>\n",
       "      <td>138</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>53</td>\n",
       "      <td>170</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>134</td>\n",
       "      <td>137</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>53</td>\n",
       "      <td>170</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>136</td>\n",
       "      <td>138</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>140</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>137</td>\n",
       "      <td>177</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>150</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>140</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78</td>\n",
       "      <td>0.4</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>103</td>\n",
       "      <td>169</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>148</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>140</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>103</td>\n",
       "      <td>170</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>148</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>140</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78</td>\n",
       "      <td>0.4</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>103</td>\n",
       "      <td>169</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>147</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>142</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>0.4</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>117</td>\n",
       "      <td>159</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>143</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2126 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LB     AC     FM     UC     DL   DS   DP  ASTV  MSTV  ALTV  ...  Width  \\\n",
       "0     120  0.000  0.000  0.000  0.000  0.0  0.0    73   0.5    43  ...     64   \n",
       "1     132  0.006  0.000  0.006  0.003  0.0  0.0    17   2.1     0  ...    130   \n",
       "2     133  0.003  0.000  0.008  0.003  0.0  0.0    16   2.1     0  ...    130   \n",
       "3     134  0.003  0.000  0.008  0.003  0.0  0.0    16   2.4     0  ...    117   \n",
       "4     132  0.007  0.000  0.008  0.000  0.0  0.0    16   2.4     0  ...    117   \n",
       "...   ...    ...    ...    ...    ...  ...  ...   ...   ...   ...  ...    ...   \n",
       "2121  140  0.000  0.000  0.007  0.000  0.0  0.0    79   0.2    25  ...     40   \n",
       "2122  140  0.001  0.000  0.007  0.000  0.0  0.0    78   0.4    22  ...     66   \n",
       "2123  140  0.001  0.000  0.007  0.000  0.0  0.0    79   0.4    20  ...     67   \n",
       "2124  140  0.001  0.000  0.006  0.000  0.0  0.0    78   0.4    27  ...     66   \n",
       "2125  142  0.002  0.002  0.008  0.000  0.0  0.0    74   0.4    36  ...     42   \n",
       "\n",
       "      Min  Max  Nmax  Nzeros  Mode  Mean  Median  Variance  Tendency  \n",
       "0      62  126     2       0   120   137     121        73         1  \n",
       "1      68  198     6       1   141   136     140        12         0  \n",
       "2      68  198     5       1   141   135     138        13         0  \n",
       "3      53  170    11       0   137   134     137        13         1  \n",
       "4      53  170     9       0   137   136     138        11         1  \n",
       "...   ...  ...   ...     ...   ...   ...     ...       ...       ...  \n",
       "2121  137  177     4       0   153   150     152         2         0  \n",
       "2122  103  169     6       0   152   148     151         3         1  \n",
       "2123  103  170     5       0   153   148     152         4         1  \n",
       "2124  103  169     6       0   152   147     151         4         1  \n",
       "2125  117  159     2       1   145   143     145         1         0  \n",
       "\n",
       "[2126 rows x 21 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardiotocography.data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(19)\n",
    "X_sample, Y_sample = random_data_sample(X, Y, 1000, rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 21)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([183, 259,  26,  36,  43, 161, 127,  44,  27,  94], dtype=int64))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_sample, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans score:  0.1860288398150711\n",
      "kmeans score (SC):  0.19692264903491544\n",
      "kmeans score (MM):  0.1860288398150711\n"
     ]
    }
   ],
   "source": [
    "test_dataset(X_sample, Y_sample, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = preprocessing.MinMaxScaler().fit_transform(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"../datasets/cardiotocography_data/X.npy\", X_sample)\n",
    "#np.save(\"../datasets/cardiotocography_data/Y.npy\", Y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = np.load(\"../datasets/cardiotocography_data/X.npy\")\n",
    "Y_sample = np.load(\"../datasets/cardiotocography_data/Y.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([183, 259,  26,  36,  43, 161, 127,  44,  27,  94], dtype=int64))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_sample, return_counts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ecoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoli = fetch_ucirepo(id=39) \n",
    "X = ecoli.data.features.values\n",
    "Y = ecoli.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Linus\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "Y = label_encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(19)\n",
    "X_sample, Y_sample = random_data_sample(X, Y, 1000, rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 7)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7]),\n",
       " array([137,  76,   1,   2,  37,  26,   5,  52], dtype=int64))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_sample, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans score:  0.46094126907932487\n",
      "kmeans score (SC):  0.46094126907932487\n",
      "kmeans score (MM):  0.46589614653749645\n"
     ]
    }
   ],
   "source": [
    "test_dataset(X_sample, Y_sample, seed=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = preprocessing.StandardScaler().fit_transform(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"../datasets/ecoli_data/X.npy\", X_sample)\n",
    "#np.save(\"../datasets/ecoli_data/Y.npy\", Y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = np.load(\"../datasets/ecoli_data/X.npy\")\n",
    "Y_sample = np.load(\"../datasets/ecoli_data/Y.npy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest Type Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['training.csv', 'testing.csv']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "# Step 1: Download the dataset\n",
    "url = \"https://archive.ics.uci.edu/static/public/333/forest+type+mapping.zip\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Step 2: Unzip the dataset\n",
    "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "    # List the contents of the zip file\n",
    "    print(z.namelist())  # Uncomment to see the list of files\n",
    "\n",
    "    # Load the specific CSV files (assuming 'training.csv' and 'testing.csv' are the main datasets)\n",
    "    with z.open('training.csv') as f:\n",
    "        train_df = pd.read_csv(f)\n",
    "        \n",
    "    with z.open('testing.csv') as f:\n",
    "        test_df = pd.read_csv(f)\n",
    "\n",
    "# Step 3: Concatenate the training and test DataFrames\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "df[\"class\"] = labelencoder.fit_transform(df[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"class\"],axis=1).values\n",
    "Y = df[\"class\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(19)\n",
    "X_sample, Y_sample = random_data_sample(X, Y, 1000, rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(523, 27)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), array([168,  84,  86, 185], dtype=int64))"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_sample, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans score:  0.46999210897765215\n",
      "kmeans score (SC):  0.20779091514147743\n",
      "kmeans score (MM):  0.46999210897765215\n"
     ]
    }
   ],
   "source": [
    "test_dataset(X_sample, Y_sample, seed=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = preprocessing.MinMaxScaler().fit_transform(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"../datasets/ForestTypeMapping_data/X.npy\", X_sample)\n",
    "#np.save(\"../datasets/ForestTypeMapping_data/Y.npy\", Y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = np.load(\"../datasets/ForestTypeMapping_data/X.npy\")\n",
    "Y_sample = np.load(\"../datasets/ForestTypeMapping_data/Y.npy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User knowledge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "user_knowledge_modeling = fetch_ucirepo(id=257) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = user_knowledge_modeling.data.features.values\n",
    "Y = user_knowledge_modeling.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Linus\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "Y = labelencoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(19)\n",
    "X_sample, Y_sample = random_data_sample(X, Y, 1000, rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 5)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4]), array([111, 129, 116,  28,  19], dtype=int64))"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_sample, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans score:  0.25701347578335876\n",
      "kmeans score (SC):  0.06420688553233227\n",
      "kmeans score (MM):  0.25701347578335876\n"
     ]
    }
   ],
   "source": [
    "test_dataset(X_sample, Y_sample, seed=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = preprocessing.MinMaxScaler().fit_transform(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"../datasets/user_knowledge_data/X.npy\", X_sample)\n",
    "#np.save(\"../datasets/user_knowledge_data/Y.npy\", Y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = np.load(\"../datasets/user_knowledge_data/X.npy\")\n",
    "Y_sample = np.load(\"../datasets/user_knowledge_data/Y.npy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Define the CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x_out = self.fc2(x)\n",
    "        return x_out, x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = transforms.Compose([transforms.Resize((28, 28)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load MNIST data\n",
    "train_data = datasets.MNIST(root=\"../datasets/mnist_data\", train=True, transform=transform, download=True)\n",
    "test_data = datasets.MNIST(root=\"../datasets/mnist_data\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Train the CNN\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Extract embeddings and labels of test data\n",
    "model.eval()\n",
    "embeddings_list = []\n",
    "labels_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        _, embeddings = model(images)\n",
    "        embeddings_list.append(embeddings.cpu().numpy())\n",
    "        labels_list.append(labels.cpu().numpy())\n",
    "\n",
    "# Save embeddings and labels to X.npy and Y.npy\n",
    "X = np.vstack(embeddings_list)\n",
    "Y = np.concatenate(labels_list)\n",
    "#np.save(\"../datasets/mnist_data/X_full.npy\", X)\n",
    "#np.save(\"../datasets/mnist_data/Y_full.npy\", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"../datasets/mnist_data/X_full.npy\")\n",
    "Y = np.load(\"../datasets/mnist_data/Y_full.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "X = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(39)\n",
    "X_sample, Y_sample = random_data_sample(X, Y, 1000, rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64),\n",
       " array([105, 109, 111, 112, 104,  86,  99,  88,  88,  98], dtype=int64))"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_sample, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans score:  0.814716314574021\n",
      "kmeans score (SC):  0.8032048085421609\n",
      "kmeans score (MM):  0.8156188428041204\n"
     ]
    }
   ],
   "source": [
    "test_dataset(X_sample, Y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"../datasets/mnist_data/X.npy\", X_sample)\n",
    "#np.save(\"../datasets/mnist_data/Y.npy\", Y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = np.load(\"../datasets/mnist_data/X.npy\")\n",
    "Y_sample = np.load(\"../datasets/mnist_data/Y.npy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yeast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeast = fetch_ucirepo(id=110) \n",
    "X = yeast.data.features.values\n",
    "Y = yeast.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Linus\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "name_encoder=LabelEncoder()\n",
    "Y=name_encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(39)\n",
    "X_sample, Y_sample = random_data_sample(X, Y, 1000, rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([319,   4,  31,  17,  28, 131, 169, 271,  12,  18], dtype=int64))"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_sample, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans score:  0.1908858405237394\n",
      "kmeans score (SC):  0.1908858405237394\n",
      "kmeans score (MM):  0.14679384946227442\n"
     ]
    }
   ],
   "source": [
    "rs = np.random.RandomState(25)\n",
    "test_dataset(X_sample, Y_sample, seed=165)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = preprocessing.StandardScaler().fit_transform(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"../datasets/yeast_data/X.npy\", X_sample)\n",
    "#np.save(\"../datasets/yeast_data/Y.npy\", Y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = np.load(\"../datasets/yeast_data/X.npy\")\n",
    "Y_sample = np.load(\"../datasets/yeast_data/Y.npy\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2022.10.undefined"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
